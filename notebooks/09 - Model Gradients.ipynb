{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable([1, 2], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    return tf.square(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y = f(x)\n",
    "tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([5, 5], dtype=tf.float16, name='fixed array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = f(x)\n",
    "tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1, 1], [5, 5]], dtype=tf.float16, name='fixed array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = f(x)\n",
    "tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sign([-5,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-shade",
   "metadata": {},
   "source": [
    "## Example with Mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def preprocess_input(input_image):\n",
    "    image = tf.cast(input_image, tf.float32)\n",
    "    resized_image = tf.image.resize(image, (224, 224))\n",
    "    return tf.keras.applications.mobilenet_v2.preprocess_input(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_layer = tf.keras.layers.Input([None, None, 3], dtype = tf.uint8)\n",
    "    processed_images = tf.keras.layers.Lambda(preprocess_input)(input_layer)\n",
    "    output = tf.keras.applications.MobileNetV2(include_top=True, weights='imagenet')(processed_images)\n",
    "    return tf.keras.Model(inputs=[input_layer], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = tf.keras.utils.get_file(\n",
    "    'YellowLabradorLooking_new.jpg', \n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'\n",
    ")\n",
    "image_raw = tf.io.read_file(image_path)\n",
    "images = tf.expand_dims(tf.image.decode_image(image_raw), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape, images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.mobilenet_v2.decode_predictions(\n",
    "    model.predict(images)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(\n",
    "    model,\n",
    "    export_dir='temp',\n",
    "    signatures=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adversarial_pattern(input_image, input_label, model):\n",
    "    loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_image)\n",
    "        prediction = model(input_image)\n",
    "        loss = loss_function(input_label, prediction)\n",
    "\n",
    "    # Get the gradients of the loss w.r.t the input image.\n",
    "    gradient = tape.gradient(loss, input_image)\n",
    "    # Get the sign of the gradients to create the perturbation\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input label of the image.\n",
    "labrador_retriever_index = 208\n",
    "label = tf.expand_dims(\n",
    "    tf.one_hot(labrador_retriever_index, 1000),\n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to compute gradients properly, we should preprocess the image before\n",
    "signed_gradients = create_adversarial_pattern(\n",
    "    preprocess_input(images),\n",
    "    label,\n",
    "    tf.keras.applications.MobileNetV2(include_top=True, weights='imagenet')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.mobilenet_v2.decode_predictions(\n",
    "    tf.keras.applications.MobileNetV2(include_top=True, weights='imagenet').predict(\n",
    "        preprocess_input(images)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.mobilenet_v2.decode_predictions(\n",
    "    tf.keras.applications.MobileNetV2(include_top=True, weights='imagenet').predict(\n",
    "        preprocess_input(images) + 1/255*signed_gradients\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-olive",
   "metadata": {},
   "source": [
    "## Custom Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(tf.math.reduce_min(first_image), tf.math.reduce_max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-pound",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('simple_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.models.load_model('simple_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "                                                 input_shape=(img_height, \n",
    "                                                              img_width,\n",
    "                                                              3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
    "sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    sunflower_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-vault",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coordinate-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(train_ds))\n",
    "_ = plt.imshow(image)\n",
    "_ = plt.title(get_label_name(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(original, augmented):\n",
    "  fig = plt.figure()\n",
    "  plt.subplot(1,2,1)\n",
    "  plt.title('Original image')\n",
    "  plt.imshow(original)\n",
    "\n",
    "  plt.subplot(1,2,2)\n",
    "  plt.title('Augmented image')\n",
    "  plt.imshow(augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = tf.image.flip_left_right(image)\n",
    "visualize(image, flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscaled = tf.image.rgb_to_grayscale(image)\n",
    "visualize(image, tf.squeeze(grayscaled))\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "saturated = tf.image.adjust_saturation(image, 3)\n",
    "visualize(image, saturated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "bright = tf.image.adjust_brightness(image, 0.4)\n",
    "visualize(image, bright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = tf.image.central_crop(image, central_fraction=0.5)\n",
    "visualize(image,cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = tf.image.rot90(image)\n",
    "visualize(image, rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "  seed = (i, 0)  # tuple of size (2,)\n",
    "  stateless_random_brightness = tf.image.stateless_random_brightness(\n",
    "      image, max_delta=0.95, seed=seed)\n",
    "  visualize(image, stateless_random_brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "  seed = (i, 0)  # tuple of size (2,)\n",
    "  stateless_random_contrast = tf.image.stateless_random_contrast(\n",
    "      image, lower=0.1, upper=0.9, seed=seed)\n",
    "  visualize(image, stateless_random_contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "  seed = (i, 0)  # tuple of size (2,)\n",
    "  stateless_random_crop = tf.image.stateless_random_crop(\n",
    "      image, size=[210, 300, 3], seed=seed)\n",
    "  visualize(image, stateless_random_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_datasets, val_ds, test_ds), metadata = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informational-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_rescale(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "  image = (image / 255.0)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "educational-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image_label, seed):\n",
    "  image, label = image_label\n",
    "  image, label = resize_and_rescale(image, label)\n",
    "  image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE + 6, IMG_SIZE + 6)\n",
    "  # Make a new seed\n",
    "  new_seed = tf.random.experimental.stateless_split(seed, num=1)[0, :]\n",
    "  # Random crop back to the original size\n",
    "  image = tf.image.stateless_random_crop(\n",
    "      image, size=[IMG_SIZE, IMG_SIZE, 3], seed=seed)\n",
    "  # Random brightness\n",
    "  image = tf.image.stateless_random_brightness(\n",
    "      image, max_delta=0.5, seed=new_seed)\n",
    "  image = tf.clip_by_value(image, 0, 1)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed generator\n",
    "# Create counter and zip together with train dataset\n",
    "counter = tf.data.experimental.Counter()\n",
    "train_ds = tf.data.Dataset.zip((train_datasets, (counter, counter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (\n",
    "    train_ds\n",
    "    .shuffle(1000)\n",
    "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = (\n",
    "    val_ds\n",
    "    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = (\n",
    "    test_ds\n",
    "    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-boulder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-steel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other way to create a generator\n",
    "rng = tf.random.Generator.from_seed(123, alg='philox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A wrapper function for updating seeds\n",
    "def f(x, y):\n",
    "  seed = rng.make_seeds(2)[0]\n",
    "  image, label = augment((x, y), seed)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-hometown",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (\n",
    "    train_datasets\n",
    "    .shuffle(1000)\n",
    "    .map(f, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = (\n",
    "    val_ds\n",
    "    .map(resize_and_rescale, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = (\n",
    "    test_ds\n",
    "    .map(resize_and_rescale, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-prophet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = Sequential([\n",
    "  layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-research",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = Sequential([\n",
    "  layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "  layers.GlobalMaxPooling2D(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-conversion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
